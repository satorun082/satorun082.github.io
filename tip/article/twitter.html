<!DOCTYPE html>

<html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=s, initial-scale=1.0">

        <link rel="stylesheet" href="../../css/article.css">
        
        <title>Twitter</title>
    </head>

    <body>

        <header>
            <h1>Twitter</h1>

            <p>Twiterで私がLikeや興味深い投稿について記述する</p>
        </header>
    
        <main>
            <ul>
                <li><a href="https://qiita.com/omiita/items/f24e4f06ae89115d248e" target="_blank"><font color="#C23685">SAM</font></a></li>
                    <p>
                        <ul>
                            <li>ICML2021で採択されるであろうOptimizerであるSAM(Sharpness-Aware Minimization)についてのQiitaでの記事</li>
                            <li>ViT(Vision Transformar)のSoTAを多くのデータセットで更新</li>
                            <li>損失が最大 and 勾配が平坦であるパラメータに更新</li>
                            <li>1回の更新で2回の勾配を計算</li>
                            <li><font color="gray">Fashion-MNISTにおけるモデルはWideResNet and PyramidNet + Shake-Shake and ShakeDrop</font></li>
                            <li>DA(Data Augmentation)も実行</li>
                            <li>過学習しにくい傾向がある</li>
                            <li>ImageNetにおけるモデルは事前学習済みEfficientNetB7</li>
                            <li><font style="background-color: #FFF280;">SAM以外にも面白い記事がリンクが多くあるので再度確認が必要</font></li>
                            <li><a href="https://twitter.com/omiita_atiimo/status/1343765981861093376?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-68-493797" target="_blank"><font color="#C23685">Transformar</font></a></li>
                    <p>
                        <ul>
                            <li>u++様によるKaggleに関する記事</li>
                            <li>Transformerライブライへのリンクあり</li>
                            <li><a href="https://twitter.com/upura0/status/1377865164511383554?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://i.ho.lc/kaggle-10-years.html" target="_blank"><font color="#C23685">Kaggle体験記</font></a></li>
                    <p>
                        <ul>
                            <li>Kaggleでの10年間の経緯についての記事</li>
                            <li>シンプルに内容が面白い</li>
                            <li>XGBoostよりも精度が良いboosting algorithmを開発している人いる(検証中とのこと)</li>
                            <li>至るところに有用なリンクが盛り込まれている(例えば,OpenCVのRANSACの精度は正しいのか...etc.)</li>
                            <li><a href="https://youtu.be/BSvP60BzoOc"><font color="#6EB7DB">tkm様のyoutube</font></a>での対談も面白い</li>
                            <li><a href="https://twitter.com/smly/status/1362207705415491585?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><font color="#C23685">Francois Chollet and Tensorflow</font></li>
                    <p>
                        <ul>
                            <li><a href="https://keras.io/examples/vision/simsiam/"><font color="#6EB7DB">Semi-Surpervised learning with SimSiam</font></a></li>
                            <li><a href="https://tfhub.dev/s?q=imagenet%20mobilenet_v3" target="_blank"><font color="#6EB7DB">MobilenetV3</font></a></li>
                            <li><a href="https://keras.io/examples/vision/perceiver_image_classification/" target="_blank"><font color="#6EB7DB">Image Classification with Perceiver</font></a></li>
                            <li><a href="https://keras.io/examples/vision/consistency_training/" target="_blank"><font color="#6EB7DB">Consistency Training with Supervision</font></a></li>
                            <li><a href="https://twitter.com/RisingSayak/status/1386483550677921794?s=20" target="_blank"><font color="#6EB7DB">[参考ツイート]Consistency Training with Supervision</font></a></li>
                            <li><a href="https://keras.io/examples/graph/node2vec_movielens/" target="_blank"><font color="#6EB7DB">Graph representation learning with node2vec</font></a></li>
                            <li><a href="https://keras.io/examples/vision/semisupervised_simclr/" target="_blank"><font color="#6EB7DB">Semi-supervied image classification using contrastive pretraining with SimCLR</font></a></li>
                            <li><a href="https://keras.io/examples/vision/siamese_contrastive/" target="_blank"><font color="#6EB7DB">Image similarity estimation using Siamese Network with a contrastive loss</font></a></li>
                            <li><a href="https://keras.io/examples/nlp/neural_machine_translation_with_transformer/" target="_blank"><font color="#6EB7DB">English-to-Spanish translation with a sequence-to-sequence Transformer</font></a></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB"></font></a></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB"></font></a></li>
                        </ul>
                    </p>
                <li><a href="https://qiita.com/omiita/items/1d96eae2b15e49235110?utm_content=buffer6586b&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer" target="_blank"><font color="#C23685">EfficientNetV2</font></a></li>
                    <p>
                        <ul>
                            <li>EfficientNetV2に関するQiita記事</li>
                            <li>その名の通り,EfficientNetのversion-2である</li>
                            <li>1/7のパラメータ数と11倍の学習速度を改善して,高い精度を実現</li>
                            <li>モデルサイズよりもデータサイズを大きくする方が精度が高い</li>
                            <li>今後はImageNet21kをデフォルトデータセットにすべき(は?,Google Landmark datasetよりも大きいやんけ)</li>
                            <li>分かりやすく読みやすい記事</li>
                            <li><a href="https://twitter.com/chizu_potato/status/1382139623623696386?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://qiita.com/jovyan/items/c41ab61a6b04e9a6e4df" target="_blank"><font color="#C23685">CTGAN</font></a></li>
                    <p>
                        <ul>
                            <li>CTGANに関するQiitaでの記事</li>
                            <li>KaggleのTPSでも使用されている認識</li>
                            <li>データ拡張などによる精度向上は,上手くいかない(個人的にも過去コンペで同様のことをした記憶があるが上手くいったことはない)</li>
                            <li><a href="https://twitter.com/currypurin/status/1377457188243787777?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://speakerdeck.com/sei88888/quan-ri-ben-cvmian-qiang-hui-fa-biao-zi-liao-learning-transformer-in-40-minutes" target="_blank"><font color="#C23685">SAM</font></a></li>
                    <p>
                        <ul>
                            <li>Transformerについてのプレゼン資料</li>
                            <li>途中のスライドにあるTransformerの図が分かりにくいというのは,疲れも重なり声を上げて笑えた</li>
                            <li>各トークン(画素や単語)の位置を考慮する為に学習不要な位置情報と共に入力情報として与える</li>
                            <li>SPEsはsinとcosの組を並べて得られるベクトルである(例: (sin(w0t), cos(w0t), sin(w1t), cos(w1t), ...)の様なベクトル)</li>
                            <li>Transformer blockはMulti-head attention, Residual connection, Layer Normalizationの3つの要素で成り立っている</li>
                            <li>難易度高なので,意味理解は不可能</li>
                            <li><a href="https://twitter.com/sei_shinagawa/status/1383659868054114311?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685">Transformarのチューニング方法</font></a></li>
                    <p>
                        <ul>
                            <li>会員限定コンテンツ</li>
                            <li><a href="https://twitter.com/stateofai_ja/status/1384327037842694148?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://copypaste-ds.hatenablog.com/entry/2019/02/08/170518" target="_blank"><font color="#C23685">Porto Seguro's Safe Driver Prediction</font></a></li>
                    <p>
                        <ul>
                            <li>ブラジル最大級の保険会社の保険金請求予測コンペティション</li>
                            <li>2値分類(確率予測)+不均衡データ</li>
                            <li>評価方法は標準化ジニ係数([0-1]で1の方が精度が良い)</li>
                            <li>上位解法がシンプルにまとめられていて読みやすい+多数のリンクがあり参考箇所が明確である</li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://github.com/QiushiWu/qiushiwu.github.io/blob/main/papers/OpenSourceInsecurity.pdf" target="_blank"><font color="#C23685">On the Feasibility of Stealthily Introducing Vulnerabilities in Open-Source Software via Hypocrite Commits</font></a></li>
                    <p>
                        <ul>
                            <li>OSSのLinux開発における脆弱性を提言</li>
                            <li><a href="https://twitter.com/niw/status/1384911866955243522?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://naotaka1128.hatenadiary.jp/entry/pandas-start-guide" target="_blank"><font color="#C23685">Pandas TIPS</font></a></li>
                    <p>
                        <ul>
                            <li>Pandasの基本的な操作からKaggleで使用可能なTipsまで幅広く解説</li>
                            <li><a href="https://twitter.com/MLBear2/status/1245137092046249984?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions" target="_blank"><font color="#C23685">Tabular Competition</font></a></li>
                    <p>
                        <ul>
                            <li>Kaggleで開催された5つのテーブルコンペ内で使用されたテクニックについて</li>
                            <li>英文で読むのに躊躇</li>
                            <li>リンク記事なので,役立ちそうな情報をリンクを辿って解決</li>
                            <li><a href="https://twitter.com/SakuEji/status/1273903581381275650?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://aria3366.hatenablog.com/entry/2021/04/01/173420" target="_blank"><font color="#C23685">Singing Voice Conversion</font></a></li>
                    <p>
                        <ul>
                            <li>音声変換</li>
                            <li>興味はあるが寝不足から流し読み</li>
                            <li>基本的にはEncoder, Decoderモデルを採用している(Attention baseチックだな)</li>
                            <li><a href="https://twitter.com/sylvan5/status/1385458491486203907?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.ricos.co.jp/isogcn/" target="_blank"><font color="#C23685">IsoGCN</font></a></li>
                    <p>
                        <ul>
                            <li>物理シミュレーションの評価を機械学習で行う</li>
                            <li>内容に興味がある人用であり,機械学習分野ではないかな</li>
                            <li><a href="https://github.com/yellowshippo/isogcn-iclr2021" target="_blank"><font color="#6EB7DB">Code</font></a></li>
                            <li><a href="https://twitter.com/RICOS_ltd/status/1384875568827617281?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://qiita.com/kenmatsu4/items/59ea3e5dfa3d4c161efb" target="_blank"><font color="#C23685">EMアルゴリズム</font></a></li>
                    <p>
                        <ul>
                            <li>コメント読んでいると分かりやすい説明となっていた.しかしながら,丁寧な説明であるが分かりやすくはない(おバカちゃんには理解出来なかった)</li>
                            <li>理解する必要がある題材</li>
                            <li><a href="https://twitter.com/tushuhei/status/1385870163862462464?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685">arXiv</font></a></li>
                    <p>
                        <ul>
                            <li><a href="https://arxiv.org/abs/2104.10325" target="_blank"><font color="#C23685">SRWarp: Generalized Image Super-Resoluition under Arbitrary Transformation</font></a></li>
                            <li><a href="https://arxiv.org/abs/2104.12533" target="_blank"><font color="#C23685">Visformer: The Vision-friendly Transformer</font></a></li>
                            <li><a href="https://arxiv.org/abs/2104.12753" target="_blank"><font color="#C23685">Improve Vision Transformars Training by Suppressing Over-smoothing</font></a></li>
                            <li><a href="https://arxiv.org/abs/2104.12807" target="_blank"><font color="#C23685">Multimodal Self-Supervised Learning of General Audio Regression</font></a></li>
                            <li><a href="https://arxiv.org/abs/2104.14548" target="_blank"><font color="#C23685">With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations</font></a></li>
                            <li><a href="https://arxiv.org/abs/2104.12909" target="_blank"><font color="#C23685">Algorithm is Experiment: Machine Learning, Market Design and Policy Eligibility Rules</font></a></li>
                            <li><a href="https://arxiv.org/abs/2105.03404" target="_blank"><font color="#C23685">ResMLP: Feedforward networks for image classification with data-efficient training</font></a></li>
                            <li><a href="https://arxiv.org/abs/2011.14211" target="_blank"><font color="#C23685">Curvature Regularization to Prevent Distortion in Graph Embedding</font></a></li>
                            <li><a href="https://arxiv.org/abs/2105.13343" target="_blank"><font color="#C23685">Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error</font></a></li>
                            <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685">Sklearn</font></a></li>
                    <p>
                        <ul>
                            <li><a href="https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.StratifiedGroupKFold.html" target="_blank"><font color="#6EB7DB">StratifiedGroupKFold</font></a></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB"></font></a></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB"></font></a></li>
                        </ul>
                    </p>
                <li><a href="https://naotaka1128.hatenadiary.jp/entry/dsb-2019-top-solution" target="_blank"><font color="#C23685">Data Science Bowl 2019</font></a></li>
                    <p>
                        <ul>
                            <li><a href="https://www.kaggle.com/c/PLAsTiCC-2018/discussion/75033" target="_blank"><font color="#6EB7DB">PLAsTiCC: 1st place solution</font></a></li>
                            <li><a href="https://arxiv.org/abs/1907.04690" target="_blank"><font color="#6EB7DB">上記論文?</font></a></li>
                            <li><a href="https://twitter.com/mamas16k/status/1368821495951020036?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://arxiv.org/abs/1807.04720" target="_blank"><font color="#C23685">A Large-Scale Study on Regularization and Normalization in GANs</font></a></li>
                    <p>
                        <ul>
                            <li>GANに関するTIPSかな</li>
                            <li>損失関数,正規化,構造,評価手法,様々な問題点など</li>
                            <li>のちのち記事にするかも</li>
                            <li><a href="https://github.com/google/compare_gan" target="_blank"><font color="#6EB7DB">Code</font></a></li>
                            <li><a href="https://twitter.com/mosko_mule/status/1018866930969694208?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://blog.albert2005.co.jp/2018/09/05/group_normalization/" target="_blank"><font color="#C23685">Group Normalization</font></a></li>
                    <p>
                        <ul>
                            <li>Group Normalizationとは</li>
                            <li>理解すべき題材</li>
                            <li><a href="https://twitter.com/sylvan5/status/1037858485554147328?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://github.com/toshi-k/kaggle-santa-2020" target="_blank"><font color="#C23685">サンタコンペ</font></a></li>
                    <p>
                        <ul>
                            <li>toshi_k様によるサンタコンペの解法及びコード</li>
                            <li><a href="https://twitter.com/toshi_k_datasci/status/1364362161196179457?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://twitter.com/campuscodi/status/1387736025657663492?s=20" target="_blank"><font color="#C23685">A long live secret backdoor with 0 VT detection</font></a></li>
                    <p>
                        <ul>
                            <li>3年以上発見されることがなかったバックドアについて</li>
                            <li><a href="https://twitter.com/campuscodi/status/1387736025657663492?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://tfhub.dev/s?publisher=tensorflow&tf-version=tf2&q=mobilebert" target="_blank"><font color="#C23685">BERT LAYER with Keras</font></a></li>
                    <p>
                        <ul>
                            <center><img src="../img/twitter/bert_layer.jfif" height="397" width="625"></center>
                            <li>BERT Layer with Tensroflow</li>
                            <li><a href="https://twitter.com/TensorFlow/status/1388191423690911745?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://iclr.cc/Conferences/2021/Schedule?type=Social" target="_blank"><font color="#C23685">ICLR2021</font></a></li>
                    <p>
                        <ul>
                            <center><img src="../img/twitter/ICLR2021.jfif" height="397" width="625"></center>
                            <li>ICLR2021の日程</li>
                            <li><a href="https://twitter.com/luisa_zintgraf/status/1388196413637644290?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://github.com/Yuki-Tanaka-33937424/kaggle-RANZCR" target="_blank"><font color="#C23685">RANZCR</font></a></li>
                    <p>
                        <ul>
                            <li>kaggleにおけるユウキ様のRANZCRコンペティション体験記</li>
                            <li>Accuracy最適化方法の論文リンクあり</li>
                            <li>詳細に書かれていおり学習過程の遷移が分かりやい</li>
                            <li>初メダルおめでとうございます!!</li>
                            <li><a href="https://twitter.com/Yuki_Kaggler/status/1375402147756470275?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.slideshare.net/cvpaperchallenge/transformer-247407256" target="_blank"><font color="#C23685">Transformerメタサーベイ</font></a></li>
                    <p>
                        <ul>
                            <li>最初の方の資料を見た気がするぞ</li>
                            <li>スライド数過多だが非常に為になるスライドである</li>
                            <li>因みに初心者+根性なし男には厳しい</li>
                            <li>ViTの蒸留なども記載されている</li>
                            <li>所感は別に畳み込みのカーネルのサイズ変更で同じような事やってくれそうとか思うのはアホなんでしょうか</li>
                            <li>CVPR2021で多くのTransformer baseの画像処理あり</li>
                            <li>ViTの使用には膨大なデータが必要</li>
                            <li>Tensorflowでも簡単にViT出来るよ</li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://digitaldigital.hatenablog.com/entry/2020/07/21/104040" target="_blank"><font color="#C23685">東大資料</font></a></li>
                    <p>
                        <ul>
                            <li>東大様によるデータ分析関連の資料</li>
                            <li>こういうのってあまり読まなかったりするよね</li>
                            <li><a href="https://twitter.com/ImAI_Eruel/status/1388459517130645505?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="http://lv4.hateblo.jp/entry/2016/12/25/235121" target="_blank"><font color="#C23685">Ethernet head</font></a></li>
                    <p>
                        <ul>
                            <li>Ethernet headの謎の2byteについて</li>
                            <li>昔は興味があったが最近はないので時間があったら読もうと思う(因みにガチ)</li>
                            <li><a href="https://twitter.com/fadis_/status/1388454636990783488?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://t.co/Kgvkv63MIJ?amp=1" target="_blank"><font color="#C23685">MIT資料</font></a></li>
                    <p>
                        <ul>
                            <li>MIT様によるデータ分析関連資料</li>
                            <li><a href="https://twitter.com/ImAI_Eruel/status/1388083116040916994?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.analyticsinsight.net/you-can-now-learn-statistics-in-these-top-10-indian-institutes/" target="_blank"><font color="#C23685">Indian Company資料</font></a></li>
                    <p>
                        <ul>
                            <li>インドの会社様によるデータ分析資料</li>
                            <li><a href="https://twitter.com/gp_pulipaka/status/1388512802785173506?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://github.com/leandromoreira/digital_video_introduction/blob/master/README-ja.md" target="_blank"><font color="#C23685">動画関連</font></a></li>
                    <p>
                        <ul>
                            <li>初学者にも読みやすい気がする</li>
                            <li>図解が多くあり非常に説明も分かりやすく全体的にawesomeです</li>
                            <li>言葉で伝わることなんて少ないのだから皆モット図解を用いよ.我の為に...</li>
                            <li><a href="https://twitter.com/tomo_makes/status/1388485925114548232?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685">BERT from scratch with Keras</font></a></li>
                    <p>
                        <ul>
                            <center><img src="../img/twitter/bert_from_scratch.jfif" width="397" height="625"></center>
                            <li>KerasでBERTを一から作成</li>
                            <li>我の為の写真である</li>
                            <li><a href="https://twitter.com/ankur310794/status/1388722220608802817?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.rstudio.com/resources/cheatsheets/" target="_blank"><font color="#C23685">CHEET SHEET</font></a></li>
                    <p>
                        <ul>
                            <li>データ分析の為のチートシート</li>
                            <li><a href="https://twitter.com/gp_pulipaka/status/1388902123933405186?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685">Amazing Image Segmentation without labeled training data</font></a></li>
                    <p>
                        <ul>
                            <li>教師なしラベルによるImage Segmentation</li>
                            <li><a href="https://twitter.com/schrep/status/1388189398496202752?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://drafts.distill.pub/ameya98/exploring-graph-nns/" target="_blank"><font color="#C23685">Understanding Convolutions on Graph</font></a></li>
                    <p>
                        <ul>
                            <li>Google Researchの人達によるGNN(Graph Neural Netwrok)の教材</li>
                            <li><a href="https://twitter.com/yellowshippo/status/1389492104385089542?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.youtube.com/watch?v=2JdUVM4NkN8&list=PLQY2H8rRoyvzSZZuF0qJpoJxZR1NgzcZw&index=20" target="_blank"><font color="#C23685">Motion Graphic</font></a></li>
                    <p>
                        <ul>
                            <li>Give a regular screen 3D abilities</li>
                            <li><a href="https://twitter.com/TensorFlow/status/1389676520390619138?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://zenn.dev/koukyo1994/articles/9b1da2482d8ba1" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li>hidehisa Arai様による自然言語関連の特徴抽出方法</li>
                            <li>コード付きで前提知識がある程度ある方には非常に役立ちそうである</li>
                            <li><a href="https://twitter.com/kaggle_araisan/status/1390318252316717057?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://oumpy.github.io/blog/2021/05/dino.html" target="_blank"><font color="#C23685">DINO</font></a></li>
                    <p>
                        <ul>
                            <li>上でも記述済みである物体認識技術</li>
                            <li><a href="https://twitter.com/oumed_python/status/1390151087978545159?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://fullstackdeeplearning.com/spring2021/" target="_blank"><font color="#C23685">UCバークレー資料</font></a></li>
                    <p>
                        <ul>
                            <li>UCバークレー様によるデータ分析資料</li>
                            <li><a href="https://twitter.com/ImAI_Eruel/status/1390624165174996992?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.kaggle.com/c/shopee-product-matching/discussion/238022" target="_blank"><font color="#C23685">2nd place solution in Shopee</font></a></li>
                    <p>
                        <ul>
                            <li>2nd place solution in Shopee</li>
                            <li>CurricularFaceの方がArcFaceよりも良いのか...AdaCosとは比較なし</li>
                            <li>Youtubeでも解説あった希ガス(日本人に生まれて良かった)</li>
                            <li><a href="https://twitter.com/MLBear2/status/1392740730104258561?s=20" target="_blank"><font color="#6EB7DB">感想Tweet</font></a></li>
                            <li><a href="https://twitter.com/lyakaap/status/1391934614592098306?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.slideshare.net/ren4yu/signate-3rd-place-solution?next_slideshow=1" target="_blank"><font color="#C23685">画像検索今昔物語</font></a></li>
                    <p>
                        <ul>
                            <li>基本的な画像検索に必要な特徴検出方法についての紹介</li>
                            <li><a href="https://twitter.com/tereka114/status/1391955854648176641?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://medium.com/rapids-ai/rapids-forest-inference-library-prediction-at-100-million-rows-per-second-19558890bc35" target="_blank"><font color="#C23685">Forest Inference</font></a></li>
                    <p>
                        <ul>
                            <li>LightGBMなどの決定木ベースのモデルの高速化</li>
                            <li><a href="https://twitter.com/asteriam_fp/status/1392037773939335169?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://upura.hatenablog.com/entry/2021/05/12/090200" target="_blank"><font color="#C23685">LightGBMの特徴量順序</font></a></li>
                    <p>
                        <ul>
                            <li>u++様によるLightGBMの特徴量の順序変更が与える影響</li>
                            <li>情報利得が同じ場合に起こる現象なのかな</li>
                            <li><a href="https://twitter.com/upura0/status/1392268788851036163?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.getrevue.co/profile/upura/issues/weekly-kaggle-news-74-598390" target="_blank"><font color="#C23685">Weekly News</font></a></li>
                    <p>
                        <ul>
                            <li>u++様によるkaggleのWeekly News</li>
                            <li><a href="https://twitter.com/upura0/status/1393059406930227202?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://github.com/google/automl/tree/master/efficientnetv2" target="_blank"><font color="#C23685">EfficientNetV2</font></a></li>
                    <p>
                        <ul>
                            <li>EfficientNetV2の実装コード</li>
                            <li><a href="https://twitter.com/tunguz/status/1393530987930210304?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.kaggle.com/its7171/map-understanding-with-code-and-its-tips?scriptVersionId=54650292" target="_blank"><font color="#C23685">mAP understanding with code and its tips</font></a></li>
                    <p>
                        <ul>
                            <li>mAPの評価指標</li>
                            <li>少数データに対する適合度が大切イムニダ</li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.getrevue.co/profile/akiratosei_ja/issues/akira-s-machine-learning-news-ja-16-474028" target="_blank"><font color="#C23685">Machine Learning News</font></a></li>
                    <p>
                        <ul>
                            <li>akira様によるmachine learning news</li>
                            <li><a href="https://twitter.com/ITS7171/status/1393836906404728840?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://medium.com/syncedreview/google-replaces-bert-self-attention-with-fourier-transform-92-accuracy-7-times-faster-on-gpus-7a78e3e4ac0e" target="_blank"><font color="#C23685">BERT</font></a></li>
                    <p>
                        <ul>
                            <li>Googleの研究チームかな?がBERTの訓練を7倍早くしたよ</li>
                            <li><a href="https://twitter.com/tunguz/status/1394414236613238785?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.kaggle.com/c/indoor-location-navigation/discussion/240176" target="_blank"><font color="#C23685">1st place solution in Indoor Location & Navigation</font></a></li>
                    <p>
                        <ul>
                            <li>1st place solution in Indoor Location & Navigation</li>
                            <li><a href="https://twitter.com/213tubo/status/1394724769837182976?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://speakerdeck.com/fam_taro/nerffalsegai-yao-to-pai-sheng-xi-nituitefalsehunwarishao-jie" target="_blank"><font color="#C23685">NeRFについて</font></a></li>
                    <p>
                        <ul>
                            <li>NeRFについて(聴講済み)</li>
                            <li><a href="https://twitter.com/fam_taro/status/1394826666162098179?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://youtu.be/5pWW9pIP94c" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li>Microsoftがmachine learningを使用しての不正ログイン検知</li>
                            <li><a href="https://twitter.com/kristinayasuda/status/1397085530106433538?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.tensorflow.org/decision_forests" target="_blank"><font color="#C23685">Decision Forest with Keras</font></a></li>
                    <p>
                        <ul>
                            <li>Decision Forest with Keras</li>
                            <li><a href="https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html" target="_blank"><font color="#6EB7DB">Introducing Tensorflow Decision Forests</font></a></li>
                            <li><a href="https://twitter.com/fchollet/status/1397358998014226432?s=20" target="_blank"><font color="#6EB7DB">Tensorflow Forum</font></a></li>
                            <li><a href="https://twitter.com/fchollet/status/1397358998014226432?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="https://www.tensorflow.org/text" target="_blank"><font color="#C23685">Text processing tools for Tensorflow</font></a></li>
                    <p>
                        <ul>
                            <li>Tensorflowでのtext処理</li>
                            <li><a href="https://twitter.com/TensorFlow/status/1397629477945966593?s=20" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
                <li><a href="" target="_blank"><font color="#C23685"></font></a></li>
                    <p>
                        <ul>
                            <li></li>
                            <li><a href="" target="_blank"><font color="#6EB7DB">Tweet</font></a></li>
                        </ul>
                    </p>
            </ul>
        </main>

        <footer>
        </footer>

    </body>

</html>