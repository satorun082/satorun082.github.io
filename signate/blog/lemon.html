<!DOCTYPE html>

<html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=s, initial-scale=1.0">

        <link rel="stylesheet" href="css/lemon.css">
        
        <title>ひろしまQuest2020</title>
    </head>

    <body>

        <header>
            <h1>ひろしまQuest2020</h1>
        </header>
    
        <main>
            <h2>所感</h2>
            <article>
                <p>
                    2月上旬には,LBで13位ぐらいだったのが,ステージ1終了時には160位ぐらいまで順位を落としてしまった.
                    理由は,LBを向上させるモデルの作成が出来なかったのである.(1位の人などは本当に驚愕である)
                    2月14日を最後にスコアが向上されることはなかった.(まじで,何やってたんだ笑)
                    また,LBに記載されている数字を叩き出したモデルを保存していなかったので,その後に作ったLBが最高値ではないモデルを提出させて頂いた.
                    今回は,VGG16, ResNet50, EfficientNetB5, EfficientNetB5, アンサンブルまで試したがあまり良い結果を得ることが出来なかったのと,LBの最高値を出したのはVGG16であったのでモデルの性能はあまり関係がないのかなぁと思った.
                </p>
                <p>
                    また,今回はリーク事件があって色々わちゃわちゃしていた印象であった.
                    私は,リークなど意にも介さず(リークに気付くだけの実力がないだけである)モデルの作成に力を注いでいたが,モデルの作成だけでなく,キチンと配布された画像を精査したり特徴を把握したりすることが大事だと思った.
                    Kaggleでは,多くの人がEDAを共有してくれるので甘えていた部分があったのかも知れない.
                    自信もcodeや考えを共有したりしたいのだが,やはり根が明るくないので,この程度の人が共有とかしてるんじゃないよと思われたくなく積極性に欠ける.
                    (今回のコンテスト中に勇気を出して共有した情報が誰も求めてない情報であることに気付き,顔から火が出るほど恥ずかしかったというのは内緒にして頂けると幸いである)
                </p>
            </article>

            <h2>自身の解法</h2>
            <article>
                <p>
                    私の解法など,需要がないことは承知であるが,自身の戒めの為に記録に残してこうと思う.
                </p>
                <p>
                    私がやったことは,Fine-Tuningのみである.
                    個人的にはFine-Tuningの方法が曖昧であるので色々実験的に試したということが正しい.
                    <br>
                    <center><img src="img/book01.jfif" height="250px" width="200px"></center>
                    <br>
                    上記の本では,入力層から最後の畳み込み層の1-3層程度まで凍結した後,学習させることをFine-Tuningと紹介していた.
                    <br>
                    <center><img src="img/book02.jfif" height="250px" width="200px"></center>
                    <br>
                    上記の本では,バックボーンは凍結させて,比較的大きな学習率で学習した後,バックボーンの凍結を解除し,小さな学習率で再学習させることをFine-Tuningで紹介していた.
                    どちらも事前学習済みモデルを使用する場合は,正しい方法なのは理解出来るが,今回はコンペティションである.
                    どちらが最適化を記載してくれていたら助かったのに...と思わずにはいられなかった.
                    結論は,後者の方が精度が少しだけ良かった.
                </p>
                <p>
                    私が主にやっていたことは各モデルにおけるFine-Tuningである.
                    加えて,EarlyStoppingとModelCheckPointを用いて,早期停止とそれまでにベストなモデルを保存していた.
                    が,コンペティションが終わった今思うことは,データ拡張を行う場合は,EarlyStoppingってそこまで効果があるのかと少しばかり疑問に思う.
                    理由は,EarlyStoppingすることにより,多くのデータ拡張が行われていないのではないか...時間があるのならば,学習中に学習率を下げていけばどのみちある程度は収束するから,そんなに焦る必要はないのではないのかと思ったのである.
                    勿論,過学習には気を付けなければならないが...
                </p>
                <p>
                    もう一つは,せっかくVGG16, ResNet50, EfficientNetB5で試していたので,アンサンブル学習をしてみようと思ったことだ.
                    因みに,先にも説明した通り,VGG16が最も良いLBを叩き出したが,EfficientNetB5が全体的に良い値を出していたので,提出したモデルはEfficientNetB5である.
                    VGG16が良いLBを出した時は,早期停止やModelCheckPointや学習率をスケジュールすることなく適当に学習していた時だったので,偶然とは恐ろしいものである.
                    またこの時に思ったのだが,早期停止などはあまり意味がなさないのではないかと言うことである.
                    EfficientNetB5においては,全体のデータを分割して作成したvalidation dataやtest dataでaccとqwkは1.0になるように学習することが出来たのだが,LBは0.94と低いのがイマイチ理解不能であった.
                    VGG16, ResNet50では, validation dataでは1.0とまではいかなくても0.98ぐらいのがLBでは0.93や0.94とEfficientNetB5とあまり変わらない値だったのが不思議でならず,ステージ1のLBは嘘付き丸なのではないかと自身の中で結論付けようかと思ったほどである.
                    結論を言うのが遅れて申し訳なかったが,アンサンブルは上手くいかなかったので,色々試すのがめんどくさくなり諦めた...
                    言い訳するのならば,当初の予定では1モデルでの精度であるからね（笑）
                    因みに,TTAなどもどなたかが質問しており,OKになったという自身の認識があるが,後で自身の理解と異なる可能性に賭けたのである.(こちらもめんどくさいが上回ったというのは内緒である)
                </p>
                <p>
                    自身が試したのは上記で全てといって良いだろう.
                    もうちょっと様々なことを試しても良かったのかもしれないが,自身の気力が追い付かなかったと言い訳させて欲しい.
                    他記事にも記載しているが,2月3月は色々と忙しかったのである.(忙しいアピール好まない)
                    少しだけ後悔している.
                </p>
            </article>

            <h2>後悔</h2>
            <article>
                <p>
                    自身への戒めとして,これぐらいはしとかなきゃいけなかった(もしくはしとけば良かった)と思うことをメモしておく.
                </p>
                <p>
                    間違いなく言えることは,特徴量を可視化して,どのような特徴を得てモデルが分類しているかを確認しておく必要があっただろう.
                    train dataにおいては,多くは白色化したりなど特徴的な情報が分類に起因していた可能性が高かった.
                    この場合,レモンの等級評価通りの特徴を取得して分類しているかどうかを判定出来たからだ.
                    今回は,複雑なモデルは必要ないと言えるので,どのように画像から特徴を得るのかがキーポイントではなかっただろうか.
                </p>
                <p>
                    初めは,交差検証法である.
                    データセットが少ない場合は,交差検証法をすることはモデルの評価をするのに有用であるということは分かっていたのに,交差検証のコードを書く+実行してモデルの評価をするという単純な作業が億劫に感じたからである.
                    データセットが少ない場合は,検証時間も比較的短いことから簡単に検証可能であると思うのだが,何をしていたことやら.
                    また,K-Fold CVなる方法や他にも様々な亜種が考えられており,自身がこれから学ぶべき事柄が多数存在することも今回理解できた.
                </p>
                <p>
                    次は,TTAである.
                    データ拡張がokayならテスト時のデータ拡張もokayだよねってことかな...?
                    一般的に,TTAは精度が向上すると思われる要素の内の1つであるので,試してみても良かったのかなぁと思われる.
                </p>
                <p>
                    時間である.
                    コンペの最後に多くの人が頑張る(もしくは隠してた人もいると思うが)影響からスコアは伸びるのである.
                    どこかのタイミングで本コンペに力を注ぐ日を決めておけば良かったと後悔している笑
                    これらは言い訳に過ぎないので,多くの人の解法を参考に自身の技術を研鑽していくことが出来れば良いなぁ...
                </p>
                <p>
                    後悔することを終わった後に足していくと結構多いので,このような形式になってしまった.（笑）
                    ここでは,<a href="http://ityuugou.jp/pdf/20200326_2.pdf">AIを活用した広島県産農産物の自動選別の研究成果</a>と題して発表された資料を確認しとけば良かったということだ.
                    コンペ終了後にTwitterで流れて来たので,コンテスト中に知り得ることはなかったと思うが,しかしながら,1つの可能性として,背景削除に力を注ぐ必要はあったのかもしれない.
                    結果として,ステージ2で背景を削除して学習していれば高い成果を上げることが出来たのかも知れない.
                </p>
            </article>

            <h2>他の人の解法</h2>
            <article>
                <ul>
                    <li><a href=""></a></li>
                    <li><a href=""></a></li>
                    <li><a href=""></a></li>
                </ul>
            </article>
        </main>

        <footer>
            <center><button class="custom-btn btn-11" onclick="location.href='https://www.nakadats.com/'">HOME</button></center>
        </footer>

    </body>

</html>